# =============================================================================
# CAM-VISION CONFIGURATION
# =============================================================================
# Copy this file to .env and fill in your values.
# All settings have sensible defaults except RTSP_URLS, which must be configured.


# -----------------------------------------------------------------------------
# CAMERA STREAMS
# -----------------------------------------------------------------------------

# RTSP URLs for your IP cameras, separated by commas.
# Each URL corresponds to one camera feed.
#
# Format: rtsp://username:password@ip:port/path
#
# Examples:
#   Single camera:
#     RTSP_URLS=rtsp://admin:mypass@192.168.1.100:554/cam/realmonitor?channel=1&subtype=0
#
#   Multiple cameras on the same NVR:
#     RTSP_URLS=rtsp://admin:mypass@192.168.1.100:554/cam/realmonitor?channel=1&subtype=0,rtsp://admin:mypass@192.168.1.100:554/cam/realmonitor?channel=2&subtype=0
#
#   Cameras from different manufacturers:
#     Dahua:   rtsp://admin:pass@IP:554/cam/realmonitor?channel=1&subtype=0
#     Hikvision: rtsp://admin:pass@IP:554/Streaming/Channels/101
#     Generic: rtsp://admin:pass@IP:554/stream1
#
#   subtype=0 is usually the main stream (high res), subtype=1 is sub stream (lower res, less bandwidth).
#   Use subtype=1 if you experience lag or high CPU usage.
#
RTSP_URLS=rtsp://admin:password@192.168.1.100:554/cam/realmonitor?channel=1&subtype=0

# Display names for each camera, separated by commas.
# Must match the number and order of RTSP_URLS.
# These names are shown on the video overlay and used as folder names for captures.
#
# Example: CAMERA_NAMES=Front Door,Backyard,Garage
#
CAMERA_NAMES=Camera_0


# -----------------------------------------------------------------------------
# FACE DETECTION
# -----------------------------------------------------------------------------

# Minimum confidence score (0.0 to 1.0) required to accept a face detection.
# The YuNet model outputs a confidence score for each detection.
# Higher values reduce false positives but may miss faces at difficult angles or poor lighting.
# Lower values detect more faces but increase false positives (leaves, shadows, textures).
#
# Recommended ranges:
#   0.60 - 0.70  Very sensitive, good for controlled environments with clear visibility
#   0.75 - 0.85  Balanced, suitable for most outdoor and indoor scenarios
#   0.85 - 0.95  Conservative, minimizes false positives at the cost of missing some faces
#
# Default: 0.85
CONFIDENCE_THRESHOLD=0.85


# -----------------------------------------------------------------------------
# FACE VALIDATION FILTERS
# -----------------------------------------------------------------------------

# Minimum face size in pixels (width and height).
# Detections smaller than this are discarded regardless of confidence.
# This prevents saving tiny, unusable face crops from distant subjects.
#
# Guidelines:
#   20  - Captures faces from very far away (low quality, more false positives)
#   40  - Standard minimum for recognizable faces (~10 meters from camera)
#   60  - Only captures reasonably close subjects (~5 meters)
#   100 - Only captures very close subjects
#
# Default: 40
MIN_FACE_SIZE=40

# Maximum aspect ratio allowed for face detections.
# Calculated as max(width, height) / min(width, height).
# Real human faces have an aspect ratio between 1.0 and 1.5.
# Elongated detections (high ratio) are typically false positives like tree branches or shadows.
#
# Guidelines:
#   1.5 - Very strict, only nearly square detections (may reject tilted faces)
#   2.0 - Recommended, filters elongated shapes while allowing natural head tilt
#   3.0 - Permissive, allows more variation but increases false positives
#
# Default: 2.0
MAX_FACE_ASPECT_RATIO=2.0


# -----------------------------------------------------------------------------
# TRACKING
# -----------------------------------------------------------------------------

# Maximum distance in pixels between centroids across consecutive frames
# to consider them the same person.
# If a face moves more than this distance between frames, it is treated as a new person.
#
# This depends on your camera resolution and how fast people move through the frame.
# For a 1080p stream at 10 FPS, a walking person moves roughly 20-50 pixels per frame.
#
# Guidelines:
#   30  - Strict tracking, works well for slow-moving or stationary subjects
#   50  - Recommended for typical surveillance scenarios
#   100 - Loose tracking, useful for fast-moving subjects or low FPS streams
#   200 - Very loose, may incorrectly merge nearby people into one ID
#
# Default: 50
TRACKING_DISTANCE=50


# -----------------------------------------------------------------------------
# PERFORMANCE
# -----------------------------------------------------------------------------

# Target frames per second for the processing loop (per camera).
# This controls how often face detection runs, NOT the video capture rate.
# The video stream always captures at the camera's native rate.
# Lower values reduce CPU/GPU usage but may miss fast-moving subjects.
#
# Guidelines:
#   5   - Low power mode, sufficient for stationary surveillance
#   10  - Recommended balance between accuracy and performance
#   15  - Higher accuracy for fast-moving scenes
#   30  - Maximum processing rate, high CPU/GPU usage
#
# Default: 10
# Target FPS for the display loop. 
# Note: Detection might be slower, but we can skip frames to maintain display FPS.
# Default: 10 (increasing this without increasing DETECTION_INTERVAL might cause lag)
TARGET_FPS=30

# Detection Interval
# Run detection every N frames.
#   1 = Detect on every frame (Slowest, most accurate)
#   2 = Detect every 2nd frame (2x faster detection loop)
#   3 = Detect every 3rd frame (Recommended for smooth video)
# Default: 3
DETECTION_INTERVAL=3


# -----------------------------------------------------------------------------
# VEHICLE DETECTION
# -----------------------------------------------------------------------------

# Minimum confidence score (0.0 to 1.0) for vehicle detections.
# The YOLOv8n model detects cars, motorcycles, buses, and trucks (COCO classes).
# Lower thresholds detect more vehicles at the cost of occasional false positives.
#
# Recommended ranges:
#   0.3 - 0.4  Very sensitive, catches distant or partially occluded vehicles
#   0.5        Balanced, suitable for most scenarios
#   0.7 - 0.8  Conservative, only high-confidence detections
#
# Default: 0.5
VEHICLE_CONFIDENCE=0.5

# Minimum vehicle bounding box size in pixels (width and height).
# Small detections are filtered out.
#
# Guidelines:
#   40  - Captures distant vehicles (may include noise)
#   60  - Standard, captures vehicles within ~30 meters
#   100 - Only nearby vehicles
#
# Default: 60
VEHICLE_MIN_SIZE=60

# Maximum centroid distance in pixels for vehicle tracking.
# Vehicles move faster than pedestrians, so this should be higher than TRACKING_DISTANCE.
#
# Guidelines:
#   50  - Strict, may lose fast vehicles between frames
#   80  - Recommended for typical traffic
#   150 - Loose, for highways or low FPS
#
# Default: 80
VEHICLE_TRACKING_DISTANCE=80


# -----------------------------------------------------------------------------
# OUTPUT
# -----------------------------------------------------------------------------

# Root directory for captured images and metadata.
# Each camera creates a subdirectory with its name.
# Faces and vehicles are saved in separate subfolders:
#
#   <OUTPUT_DIR>/
#     <CameraName>/
#       person_0/
#         face.jpg          - Cropped face image
#         body.jpg          - Estimated full body crop
#         metadata.json     - Detection metadata (timestamp, bbox, confidence)
#       vehicle_0/
#         vehicle_crop.jpg  - Cropped vehicle image
#         metadata.json     - Vehicle metadata (class, timestamp, bbox, confidence)
#       person_1/
#         ...
#
# Default: rostros_detectados
OUTPUT_DIR=rostros_detectados

# -----------------------------------------------------------------------------
# IMAGE ENHANCEMENT
# -----------------------------------------------------------------------------

# Contrast Limited Adaptive Histogram Equalization (CLAHE) clip limit.
# Controls how much contrast is added. Higher values = more contrast but more noise.
# Range: 1.0 (low) to 4.0 (high)
# Default: 2.0
ENHANCE_CLAHE_CLIP=2.0

# Sharpening amount (Unsharp Masking).
# Controls how crisp the image edges appear.
# Range: 0.5 (subtle) to 2.0 (strong)
# Default: 1.5
ENHANCE_SHARPEN_AMOUNT=1.5
