# =============================================================================
# CAM-VISION CONFIGURATION
# =============================================================================
# Copy this file to .env and fill in your values.
# All settings have sensible defaults except RTSP_URLS, which must be configured.


# -----------------------------------------------------------------------------
# CAMERA STREAMS
# -----------------------------------------------------------------------------

# RTSP URLs for your IP cameras, separated by commas.
# Each URL corresponds to one camera feed.
#
# Format: rtsp://username:password@ip:port/path
#
# Examples:
#   Single camera:
#     RTSP_URLS=rtsp://admin:mypass@192.168.1.100:554/cam/realmonitor?channel=1&subtype=0
#
#   Multiple cameras on the same NVR:
#     RTSP_URLS=rtsp://admin:mypass@192.168.1.100:554/cam/realmonitor?channel=1&subtype=0,rtsp://admin:mypass@192.168.1.100:554/cam/realmonitor?channel=2&subtype=0
#
#   Cameras from different manufacturers:
#     Dahua:   rtsp://admin:pass@IP:554/cam/realmonitor?channel=1&subtype=0
#     Hikvision: rtsp://admin:pass@IP:554/Streaming/Channels/101
#     Generic: rtsp://admin:pass@IP:554/stream1
#
#   subtype=0 is usually the main stream (high res), subtype=1 is sub stream (lower res, less bandwidth).
#   Use subtype=1 if you experience lag or high CPU usage.
#
RTSP_URLS=rtsp://admin:password@192.168.1.100:554/cam/realmonitor?channel=1&subtype=0

# Display names for each camera, separated by commas.
# Must match the number and order of RTSP_URLS.
# These names are shown on the video overlay and used as folder names for captures.
#
# Example: CAMERA_NAMES=Front Door,Backyard,Garage
#
CAMERA_NAMES=Camera_0


# -----------------------------------------------------------------------------
# FACE DETECTION
# -----------------------------------------------------------------------------

# Minimum confidence score (0.0 to 1.0) required to accept a face detection.
# The YuNet model outputs a confidence score for each detection.
# Higher values reduce false positives but may miss faces at difficult angles or poor lighting.
# Lower values detect more faces but increase false positives (leaves, shadows, textures).
#
# Recommended ranges:
#   0.60 - 0.70  Very sensitive, good for controlled environments with clear visibility
#   0.75 - 0.85  Balanced, suitable for most outdoor and indoor scenarios
#   0.85 - 0.95  Conservative, minimizes false positives at the cost of missing some faces
#
# Default: 0.85
CONFIDENCE_THRESHOLD=0.85


# -----------------------------------------------------------------------------
# FACE VALIDATION FILTERS
# -----------------------------------------------------------------------------

# Minimum face size in pixels (width and height).
# Detections smaller than this are discarded regardless of confidence.
# This prevents saving tiny, unusable face crops from distant subjects.
#
# Guidelines:
#   20  - Captures faces from very far away (low quality, more false positives)
#   40  - Standard minimum for recognizable faces (~10 meters from camera)
#   60  - Only captures reasonably close subjects (~5 meters)
#   100 - Only captures very close subjects
#
# Default: 40
MIN_FACE_SIZE=40

# Maximum aspect ratio allowed for face detections.
# Calculated as max(width, height) / min(width, height).
# Real human faces have an aspect ratio between 1.0 and 1.5.
# Elongated detections (high ratio) are typically false positives like tree branches or shadows.
#
# Guidelines:
#   1.5 - Very strict, only nearly square detections (may reject tilted faces)
#   2.0 - Recommended, filters elongated shapes while allowing natural head tilt
#   3.0 - Permissive, allows more variation but increases false positives
#
# Default: 2.0
MAX_FACE_ASPECT_RATIO=2.0


# -----------------------------------------------------------------------------
# TRACKING
# -----------------------------------------------------------------------------

# Maximum distance in pixels between centroids across consecutive frames
# to consider them the same person.
# If a face moves more than this distance between frames, it is treated as a new person.
#
# This depends on your camera resolution and how fast people move through the frame.
# For a 1080p stream at 10 FPS, a walking person moves roughly 20-50 pixels per frame.
#
# Guidelines:
#   30  - Strict tracking, works well for slow-moving or stationary subjects
#   50  - Recommended for typical surveillance scenarios
#   100 - Loose tracking, useful for fast-moving subjects or low FPS streams
#   200 - Very loose, may incorrectly merge nearby people into one ID
#
# Default: 50
TRACKING_DISTANCE=50


# -----------------------------------------------------------------------------
# PERFORMANCE
# -----------------------------------------------------------------------------

# Target frames per second for the processing loop (per camera).
# This controls how often face detection runs, NOT the video capture rate.
# The video stream always captures at the camera's native rate.
# Lower values reduce CPU/GPU usage but may miss fast-moving subjects.
#
# Guidelines:
#   5   - Low power mode, sufficient for stationary surveillance
#   10  - Recommended balance between accuracy and performance
#   15  - Higher accuracy for fast-moving scenes
#   30  - Maximum processing rate, high CPU/GPU usage
#
# Default: 10
TARGET_FPS=10


# -----------------------------------------------------------------------------
# OUTPUT
# -----------------------------------------------------------------------------

# Root directory for captured images and metadata.
# Each camera creates a subdirectory with its name.
# Inside each camera directory, each detected person gets a folder:
#
#   <OUTPUT_DIR>/
#     <CameraName>/
#       person_0/
#         face.jpg          - Cropped face image
#         body.jpg          - Estimated full body crop
#         metadata.json     - Detection metadata (timestamp, bbox, confidence)
#       person_1/
#         ...
#
# Default: rostros_detectados
OUTPUT_DIR=rostros_detectados
